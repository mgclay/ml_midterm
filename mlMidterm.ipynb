{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = pd.read_csv('train_with_label.txt', sep = '\\t', \\\n",
    "                              names = ['instance_id', 'sentence1', 'sentence2', 'label'], \\\n",
    "                             quoting = 3)\n",
    "\n",
    "train_df = pd.DataFrame(train_sentences)\n",
    "# train_df = train_df.replace(np.nan,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    sent1 = df.loc[:, 'sentence1']\n",
    "    sent2 = df.loc[:, 'sentence2']\n",
    "    labels = df.loc[:, 'label']\n",
    "    \n",
    "    return sent1, sent2, labels\n",
    "\n",
    "train_sent1, train_sent2, train_labels = get_data(train_df)\n",
    "\n",
    "def get_data_test(df):\n",
    "    sent1 = df.loc[:, 'sentence1']\n",
    "    sent2 = df.loc[:, 'sentence2']\n",
    "    testid = df.loc[:, 'instance_id']\n",
    "    return sent1, sent2, testid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokall1 = []\n",
    "tokall2 = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    rx =  r\"['()\\w]+|\\.\"\n",
    "    tok1 = []\n",
    "    tok2 = []\n",
    "    \n",
    "    s1 = train_sent1[i]\n",
    "    s2 = train_sent2[i]\n",
    "    \n",
    "    tok1 += re.findall(rx, s1)\n",
    "    tok2 += re.findall(rx, s2)\n",
    "    \n",
    "    tokall1.append([t.lower() for t in tok1])\n",
    "    tokall2.append([t.lower() for t in tok2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toktotal1 = [item for s in tokall1 for item in s]\n",
    "toktotal2 = [item for s in tokall2 for item in s]\n",
    "\n",
    "tokevery = toktotal1 + toktotal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vectorizer.fit_transform(tokevery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecall1 = tokall1\n",
    "vecall2 = tokall2\n",
    "for i in range(len(tokall1)):\n",
    "    vecall1[i] = vectorizer.transform(tokall1[i]).toarray().mean(axis = 0)\n",
    "    \n",
    "for i in range(len(tokall2)):\n",
    "    vecall2[i] = vectorizer.transform(tokall2[i]).toarray().mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(penalty = 'l2', solver = 'newton-cg', \\\n",
    "                               class_weight = 'balanced', max_iter = 500)\n",
    "\n",
    "# diffs = np.array(vecall1) + np.array(vecall2[i])\n",
    "\n",
    "diffs = np.concatenate((np.array(vecall1), np.array(vecall2)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=500, solver='newton-cg')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(diffs, train_labels)\n",
    "#svm_model.fit(diffs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956831003188619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(diffs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956831003188619\n"
     ]
    }
   ],
   "source": [
    "preds = log_model.predict(diffs)\n",
    "\n",
    "# for i in range(len(sim_mat)):\n",
    "#     if sim_mat[i][i] >= 0.5:\n",
    "#         preds[i] = 1\n",
    "        \n",
    "print(accuracy_score(train_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dev set on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = pd.read_csv('dev_with_label.txt', sep = '\\t', \\\n",
    "                            names = ['instance_id', 'sentence1', 'sentence2', 'label'],\\\n",
    "                           quoting = 3)\n",
    "\n",
    "dev_df = pd.DataFrame(dev_sentences)\n",
    "# dev_df = dev_df.replace(np.nan,0) \n",
    "\n",
    "dev_sent1, dev_sent2, dev_labels = get_data(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tokall1 = []\n",
    "dev_tokall2 = []\n",
    "\n",
    "for i in range(len(dev_df)):\n",
    "    rx =  r\"['()\\w]+|\\.\"\n",
    "    tok1 = []\n",
    "    tok2 = []\n",
    "    \n",
    "    s1 = dev_sent1[i]\n",
    "    s2 = dev_sent2[i]\n",
    "    \n",
    "    tok1 += re.findall(rx, s1)\n",
    "    tok2 += re.findall(rx, s2)\n",
    "    \n",
    "    dev_tokall1.append([t.lower() for t in tok1])\n",
    "    dev_tokall2.append([t.lower() for t in tok2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_vecall1 = dev_tokall1\n",
    "dev_vecall2 = dev_tokall2\n",
    "for i in range(len(dev_tokall1)):\n",
    "    dev_vecall1[i] = vectorizer.transform(dev_tokall1[i]).toarray().mean(axis = 0)\n",
    "    \n",
    "for i in range(len(dev_tokall2)):\n",
    "    dev_vecall2[i] = vectorizer.transform(dev_tokall2[i]).toarray().mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606353591160221\n"
     ]
    }
   ],
   "source": [
    "dev_labels = list(dev_labels)\n",
    "\n",
    "for i in range(len(dev_labels)):\n",
    "    try:\n",
    "        dev_labels[i] = int(dev_labels[i])\n",
    "    except:\n",
    "        dev_labels[i] = 0\n",
    "\n",
    "# dev_diffs = np.array(dev_vecall1) + np.array(dev_vecall2)\n",
    "\n",
    "dev_diffs = np.concatenate((np.array(dev_vecall1), np.array(dev_vecall2)),\\\n",
    "                           axis = 1)\n",
    "\n",
    "dev_preds = log_model.predict(dev_diffs)\n",
    "\n",
    "print(accuracy_score(dev_labels, dev_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing test set on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = pd.read_csv('dev_with_label.txt', sep = '\\t', \\\n",
    "                              names = ['instance_id', 'sentence1', 'sentence2', 'label'], \\\n",
    "                             quoting = 3)\n",
    "\n",
    "dev_df = pd.DataFrame(train_sentences)\n",
    "\n",
    "dev_sent1, dev_sent2, dev_labels = get_data(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokall1 = []\n",
    "tokall2 = []\n",
    "\n",
    "for i in range(len(dev_df)):\n",
    "    rx =  r\"['()\\w]+|\\.\"\n",
    "    tok1 = []\n",
    "    tok2 = []\n",
    "    \n",
    "    s1 = dev_sent1[i]\n",
    "    s2 = dev_sent2[i]\n",
    "    \n",
    "    tok1 += re.findall(rx, s1)\n",
    "    tok2 += re.findall(rx, s2)\n",
    "    \n",
    "    tokall1.append([t.lower() for t in tok1])\n",
    "    tokall2.append([t.lower() for t in tok2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "toktotal1 = [item for s in tokall1 for item in s]\n",
    "toktotal2 = [item for s in tokall2 for item in s]\n",
    "\n",
    "tokevery = toktotal1 + toktotal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vectorizer.fit_transform(tokevery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecall1 = tokall1\n",
    "vecall2 = tokall2\n",
    "for i in range(len(tokall1)):\n",
    "    vecall1[i] = vectorizer.transform(tokall1[i]).toarray().mean(axis = 0)\n",
    "    \n",
    "for i in range(len(tokall2)):\n",
    "    vecall2[i] = vectorizer.transform(tokall2[i]).toarray().mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = list(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model2 = LogisticRegression(penalty = 'l2', solver = 'newton-cg', \\\n",
    "                               class_weight = 'balanced', max_iter = 500)\n",
    "\n",
    "# diffs = np.array(vecall1) + np.array(vecall2[i])\n",
    "\n",
    "diffs = np.concatenate((np.array(vecall1), np.array(vecall2)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=500, solver='newton-cg')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model2.fit(diffs, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = pd.read_csv('test_without_label.txt', sep = '\\t', \\\n",
    "                            names = ['instance_id', 'sentence1', 'sentence2'],\n",
    "                           quoting = 3)\n",
    "\n",
    "test_df = pd.DataFrame(test_sentences)\n",
    "# dev_df = dev_df.replace(np.nan,0) \n",
    "\n",
    "test_sent1, test_sent2, test_id = get_data_test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokall1 = []\n",
    "test_tokall2 = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    rx =  r\"['()\\w]+|\\.\"\n",
    "    tok1 = []\n",
    "    tok2 = []\n",
    "    \n",
    "    s1 = test_sent1[i]\n",
    "    s2 = test_sent2[i]\n",
    "    \n",
    "    tok1 += re.findall(rx, s1)\n",
    "    tok2 += re.findall(rx, s2)\n",
    "    \n",
    "    test_tokall1.append([t.lower() for t in tok1])\n",
    "    test_tokall2.append([t.lower() for t in tok2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecall1 = test_tokall1\n",
    "test_vecall2 = test_tokall2\n",
    "for i in range(len(test_tokall1)):\n",
    "    test_vecall1[i] = vectorizer.transform(test_tokall1[i]).toarray().mean(axis = 0)\n",
    "    \n",
    "for i in range(len(test_tokall2)):\n",
    "    test_vecall2[i] = vectorizer.transform(test_tokall2[i]).toarray().mean(axis = 0)\n",
    "    \n",
    "test_id = list(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(predictions, test_id):\n",
    "    with open(\"MaryClay_test_result.txt\", \"a\") as f:\n",
    "        print(\"instance_id\\tpredicted_label\\n\", file=f)\n",
    "        for i in range(0, len(predictions)):\n",
    "            print(predictions[i],\"\\t\", test_id[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_diffs = np.concatenate((np.array(test_vecall1), np.array(test_vecall2)),\n",
    "                           axis = 1)\n",
    "\n",
    "preds = log_model2.predict(test_diffs)\n",
    "print_predictions(preds, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
